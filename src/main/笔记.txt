Synchronize语义规范：
  1、进入同步块前，先清空工作内存中的共享变量，从主内存中重新加载（也能实现变量的可见性）
  2、解锁前必须把修改的共享变量同步回主内存
volatile语义规范：
  1、使用volatile变量时，必须重新从主内存加载，并且read、load是连续的
  2、修改volatile变量后，必须立马同步回主内存，并且store、write是连续的

-------------------JVM运行时数据区-------------------
一、线程共享部分
  1、方法区
     存储加载的类信息、常量、静态变量、JIT编译后端代码数据
  2、堆内存
     存放对象实例，几乎所有对象、数组都放这里
     回收判断：引用计数器法、可达性分析算法
     默认比例：老年代占2/3，新时代占1/3（Eden占8/10，s0占1/10，s1占1/10）
     JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。
     因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间
二、线程独占部分
  1、虚拟机栈
     线程中方法执行的模型，每个方法执行时，就会在虚拟机中创建一个栈帧，每个方法从调用到执行的过程，就对应着栈帧在虚拟机中从入栈到出栈的过程
     栈帧包括：局部变量表（存放局部变量基础类型值），局部对象的引用，操作数栈（存放临时变量），返回值地址
  2、本地方法栈
     和虚拟机栈类似，虚拟机栈是为执行java方法而准备的。本地方法栈是为虚拟机使用native方法而准备的
  3、程序计数器
     记录cpu执行到字节码指令的位置，线程切换需要

直接内存：JVM之外的内存，开发人员自己分配和回收内存


Lock和synchronized的选择
  1、Lock是接口，而synchronized是java中的关键字
  2、synchronized会自动释放锁，而Lock需要手动释放锁
  3、Lock可以让等待锁的线程响应中断，而synchronized却不行
  4、通过Lock可以知道有没有成功获得锁，而synchronized却无法办到
  5、Lock可以提供多个线程进行读操作
  6、当竞争资源非常激烈时，Lock的性能要远远大于synchronized

自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环（减少了上下文切换）

synchronized的锁升级:
  对象头里保存了锁的状态：无锁、偏向锁、轻量级锁、重量级锁。锁只能升级不能降级
  1、偏向锁：默认这个锁属于A，当A再次拿锁就直接给他，B来拿锁，发现是偏向A的，就去尝试获取锁，成功了就偏向B，否则升级为轻量级锁。用CAS设置偏向锁
  2、轻量级锁：A获取了锁，B来拿锁，先自旋一段时间，如果自旋完还没拿到锁就升级到重量级锁，B阻塞
  3、重量级锁：A获取了锁，B来拿锁，没拿到就直接阻塞了

分布式锁实现的几种方案
  1、数据库实现（乐观锁）
  2、基于zookeeper实现
  3、基于redis实现。redis调用lua脚本，原子操作设置key和超时时间。推荐redission包，redis官方jar包

常用的数据库优化方法：
  1、建索引
  2、分区表

索引的原理：
  对列值创建排序存储，数据结构={列值、行地址}。在有序的数据列表中就可以利用二分查找快速找到要查找的行地址，在根据地址直接取行数据
  mysql使用B+树存储索引

唯一id生成方法：
  1、UUID
  2、数据库自增，分库分表的时候可以设置不同表的起始值和步长不同达到全局唯一的效果
  3、雪花算法
  4、redis
  5、AtomicInteger

弱引用--WeekReference
  当一个对象仅仅被weak reference指向, 而没有任何其他strong reference指向的时候, 如果GC运行, 那么这个对象就会被回收

软引用--SoftReference
  用法和弱引用一样，回收的时候再加一个条件：内存不足的时候才会回收

GC roots
  1、通过System Class Loader或者Boot Class Loader加载的class对象
  2、线程栈变量
  3、静态变量
  4、常量池
  5、jni指针
  6、正在被用于同步的各种锁对象
GC 算法
  1、标记清除
  2、复制
  3、标记整理
永久代和元空间区别：
  1、永久代必须指定大小，元空间默认无上限
  2、字符串常量1.7放永久代，1.8后放在堆里
  3、元空间由操作系统管理
jvm GC
  Minor GC：清理新生代，Eden区满了会触发一次（把根引用对象复制到s0或者s1区域，并且把对象的分代年龄+1，分带年龄大于15的对象会进入到老年代。可回收对象就直接清理掉）
  Major GC：Full GC
  Full GC：清理整个堆，包括新生代和老年代
  https://www.cnblogs.com/yuyutianxia/p/8986902.html
  shallow heap：这个对象实际占用的堆大小（ 类定义引用大小 + 父类的成员变量所占的空间 + 当前类的成员变量所占的空间 + 结构体对齐）
  retained heap：如果这个对象被删除了（GC回收掉），能节省出多少内存
  -XX:SurvivorRatio=6 ，设置的是Eden区与每一个Survivor区的比值，可以反推出占新生代的比值，Eden为6, 两个Survivor为2, Eden占新生代的3/4, 每个Survivor占1/8，两个占1/4

Full GC触发条件：
  1、System.gc()方法的调用。此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定，但很多情况下它会触发 Full GC
  2、老年代空间不足。新生代对象转入 或者 创建为大对象、大数组时 发现老年代空间不足
  3、方法区空间不足。CMS GC可避免这个问题
  4、判断当前新生代的对象是否能够全部顺利的晋升到老年代，如果不能，就提早触发一次老年代的收集
  5、CMS GC时出现promotion failed和concurrent mode failure时：进行Minor GC时，survivor space放不下, 对象只能放入老年代，而此时老年代也放不下

如何减少Full GC次数：
  1、尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间（加大新生代的空间，降低Minor GC的频率）
  2、不要创建过大的对象及数组（因为数组需要连续空间）
  3、CMS模式里，Full GC之后额外免费赠送一个碎片整理的过程。XX:+UseCMSCompactAtFullCollection（默认开启的）
     执行多少次不压缩的Full GC后,跟着来一次带压缩的。-XX:CMSFullGCsBeforeCompaction （默认值为0，表示每次Full GC是都进行碎片整理），可降低STW的时间
  4、禁止使用System.gc()方法

CMS收集器：
  过程：初始标记、并发标记、重新标记、并发清除
  缺点：1、对CPU资源敏感。默认启动回收线程数=(CPU数量+3)/4，CPU小于4个的时候，对CPU资源占用较大
        2、无法处理浮动垃圾，并发清除阶段，用户线程会产生新的垃圾，CMS只能下次回收
  -XX:CMSInitiatingOccupancyFraction = 92 ：当老年代内存使用了92%就启用CMS收集。这个值如果设置的太大，那么导致并发清除的时候，预留给用户线程的内存不够，
     会出现Concurrent Mode Failure失败。这时候jvm会启动Serial Old收集器来重新收集老年代，这样停顿的时间就长了

G1（Garbage First）收集器：
  开启选项：-XX:+UseG1GC
  使用copy算法
  化整为零的思路：将java堆划分为多个大小相等的独立区域（Region）
  可停顿的预测：使用者可以明确指定在M毫秒的时间片段内，GC不超过N毫秒
  维护一个优先级列表，优先回收价值最大的Region
  运作期间不会产生内存空间碎片，收集后能提供连续的可用内存
  过程：初始标记、并发标记、最终标记、筛选回收

jvm参数分类：
  1、-开头，所有HotSpot都支持
  2、-X开头，
  3、-XX开头，下个版本可能取消


netty两个线程池作用
  一个负责接受客户端的TCP连接
  一个负责处理I/O相关的读写操作，或执行系统task、定时task。一个线程对应多个链路，一个链路对应一个线程，避免并发
特定Hotspot版本支持
redis慢查询日志：
  slowlog-log-slower-than：慢查询预定阀值
  slowlog-max-len:先进先出队列的长度，超过长度后新日志进入会删除老日志（所以可以定期用slowlog get命令获取日志并保持到mysql里）
  慢查询日志记录的是命令执行时间超过阀值的命令，客户端命令执行时间 = 排队等待时间 + 执行时间 + 网络传输时间
  当客户端命令执行时间过长，排查过程：如果慢查询日志里没有，用redis监控看连接数是否大于最大连接数，看是否RDB占用了很多时间

类加载过程：
  加载-->验证-->准备-->解析-->初始化
  内部类只有在使用的时候才会被加载，可利用这一特性写单例模式（避免过早初始化的问题）
  枚举不能被反射创建

aop 应用场景：日志，事务，权限,参数校验
    实现原理是动态代理
    spring的AOP实现
    1、jdk动态代理
    2、采用Cglib动态代理可以对没有实现接口的类产生代理，实际上是生成了目标类的子类来增强。
mybatis的Mapper使用了动态代理创建Dao
静态代理模式：
   接口
   被代理类：实现接口
   代理类：实现接口 + 引用真实类
   这样代理就可以对外提供接口的所有方法（可选择用被代理类实现，或自己实现这些方法）
动态代理模式：
   反射方式实现，避免实现所有接口的所有方法(jdk动态帮我们创建一个类(字节码文件),以$Proxy开头)
   代理类的调用方法
   invoke（Method method）{
      if(method 是需要我自己实现的){
         我就自己实现
         return
      }
      //被代理类去实现
      method.invoke()
   }


class文件的开头是一个魔数：0xCAFEBABE
mybatis分页插件

线程池执行任务流程：
   1 使用核心线程执行
   2 核心线程数满了，放入队列
   3 队列满了，使用临时线程
   4 临时线程数满了，使用拒绝策略

上下文切换带来的损耗
   1、CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉
   2、多核的cache之间得共享数据
   https://www.jianshu.com/p/5549e89133d2

线程池大小设置：
    cpu密集型：cup核心数 + 1 （cpu的利用率高，不用开太多的线程，开太多线程反而会因为线程切换时切换上下文而浪费资源）
    io密集型：cup核心数 * 2 （因为IO操作会阻塞线程，cpu利用率不高，可以开多点线程，阻塞时可以切换到其他就绪线程，提高cpu利用率）
    实际应用：cup核心数 *（1 + 线程等待时间 / 线程运行时间）

御龙在天线程模型：
    玩家线程：一个队列，一个（单线程）线程池，多个玩家共用一个队列。总共CPU核数 * 2个队列
    db线程池：CPU核数 * 2
    定时器线程池：CPU核数 * 2
    场景线程：CPU核数 * 2。用来100毫秒刷新一次场景，同一个场景同一时刻只有一个线程执行
              两个定时器用同一个线程池执行任务：一个定时器刷新玩家视野；一个定时器刷新怪物状态，ai，复活，产生新的怪物，执行延迟技能
              刷新视野：遍历地图对象，如果有位置变化，把自己更新到周围格子；玩家视野边长范围2-6格子；每个格子记录可以看到这个格子的玩家
TCP三次握手：
   可以理解为应该4次握手合并成了三次，每个端都需要一问一答才能确立连接。
   c问s答，c确认建立连接；s问c答，s确认建立连接。syn是问，ack是答
   但是服务器把答（ack）和问（syn）一次性发送过去了。
   第三次握手是为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误。
TCP四次挥手：
   每个端都需要一问一答才能确认关闭 。请求关闭（FIN），回答（ACK）
   为什么不是三次？
   因为服务器的问答不能合并发送了
   因为服务端接到客户端关闭请求后，自己可能还有消息要处理，所以不能立马告诉客户端我要关闭，要等消息处理完再发送关闭请求。
   服务器比客户端先关闭连接，因为客户端发送最后一个ack后，会启动一个计时器。计时器到了，才关闭连接。而服务器接收到ack就立马close。这么做是防止最后一个ack丢失
TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。
服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。
若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接

TCP保证可靠性：
  1、确认机制：每个段都有序列号（前一个段的序号+字节长度），收到段后返回确认号（收到段的序号+字节长度），若确认号为= N，则表明：到序号N-1为止的所有数据都已正确收到
  2、重传机制：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。定时器的时间是动态计算的
  3、滑动窗口：TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出(不用等ack，可以连续发送多个包)
               接收端处理数据的速度是有限的. 如果发送端发的太快, 导致接收端的缓冲区被打满, 这个时候如果发送端继续发送, 就会造成丢包, 继而引起丢包重传等等一系列连锁反应.
  在网络不好的情况下，tcp的延时会加重，重传时间变的更长

UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。简单来说，当一台计算机向另外一台计算机发送数据时，发送端不会确认接收端是否存在，就会发出数据，同样接收端在收到数据时，也不会向发送端反馈是否收到数据。
由于使用UDP协议消耗资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输例如视频会议都使用UDP协议，因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。
但是在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议。
UDP传输数据被限制在64K以内,在内网传输，最好控制在1472字节(1500-8-20),在内网传输，最好控制在1472字节(1500-8-20)

Snappy压缩库
Snappy是Google开源的压缩/解压缩库。和其他压缩库相比，snappy的压缩率并不是最高的，兼容性也并非最好的。相反，它的诞生旨在以极高的压缩/解压缩速率提供合理的压缩率。
Snappy官指出：在64位单核core-i7处理器下，snappy的压缩率能够达到250MB/S，而解压缩速度则能达到500MB/S。
目前很多软件使用（或支持）snappy作为压缩库，如MongoDB,Cassandra,Hadoop,Lucene

迭代器
  一种设计模式
  不同集合的内部数据结构不一样，遍历方式也不一样。利用迭代器统一实现遍历，不同集合内部实现方式不一样，但是对外使用都是一样的。
  Iterable 接口提供获取Iterator方法，并且实现这个接口可以用foreach遍历
  Iterator 提供遍历的方法

clone
  Object的clone方法是native方法，是protected，只有子类能调用
  子类只有实现了Cloneable接口才能调用Object的clone()方法，否则报错
  Object的clone()方法会创建一个新对象，对象的成员变量和老的对象一样，包括基础类型和引用类型

java使用Unicode编码：Unicode编码则是采用双字节16位来进行编号，可编65536字符，是全世界一种通用的编码

线程安全的list
  1、CopyOnWriteArrayList
  2、Collections.synchronizedList(new ArrayList<>())
  3、Vector
    Vector，它是ArrayList的线程安全版本，其实现90%和ArrayList都完全一样，区别在于：
    1、Vector是线程安全的，ArrayList是线程非安全的
    2、Vector可以指定增长因子，如果该增长因子指定了，那么扩容的时候会每次新的数组大小会在原数组的大小基础上加上增长因子；
       如果不指定增长因子，那么就给原数组大小*2
线程安全的map
  1、HashTable
  2、Collections.synchronizedMap(new HashMap<>())
  3、ConcurrentHashMap
线程安全的queue
  1、ConcurrentLinkedQueue  全程采用cas，无锁操作，避免线程的上下文切换。无法设置队列大小
  2、ArrayBlockingQueue   put 和 get 用同一个 ReenterLock。Condition实现阻塞，唤醒。不会封装Node节点，减少对象的创建。必须设置大小
  3、LinkedBlockingQueue  put 和 get 锁分离。Condition实现阻塞，唤醒。可以设置队列大小
  4、SynchronousQueue     put一定阻塞，有人拿走了我的消息，我就被唤醒
  5、LinkedTransferQueue  融合了ConcurrentLinkedQueue、LinkedBlockingQueue、SynchronousQueue（公平模式）
  6、PriorityBlockingQueue 按优先级出队（元素实现Comparable，或者指定Comparator）
  7、DelayQueue  队列里用了PriorityQueue存数据，所以是有序出队，每个元素还有一个延时时间，到了延时时间才能出队
  8、Disruptor框架：是由LMAX公司开发的一款高效的无锁内存队列
  https://www.jianshu.com/p/ae6977886cec

缓存穿透：请求数据，在redis里没找到，然后到数据库去查找也没找到，这个就叫穿透。用户可以用很多无效id请求攻击服务器，占用数据库资源。
解决方案：布隆过滤器，将id用多个hash算法计算出多个指纹，将指纹放入bitmap里。如果布隆过滤器说没有那就一定没有，说有那就可能有。
          布隆过滤器可用于海量数据里判断出某个数据是否存在
缓存击穿：当缓存key失效的瞬间，大量请求访问key，造成数据库压力过大
解决方案：设置互斥锁，当缓存不存在，尝试去获取锁，获取到锁了去数据库加载并设置到缓存；没有获取到锁就休眠一会再获取数据

缓存雪崩：大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩
解决方案：可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效

redis数据淘汰策略
    1、volatile-lru:从已设置过期的数据集中挑选最近最少使用的淘汰
    2、volatile-ttr:从已设置过期的数据集中挑选将要过期的数据淘汰
    3、volatile-random:从已设置过期的数据集中任意挑选数据淘汰
    4、allkeys-lru:从数据集中挑选最近最少使用的数据淘汰
    5、allkeys-random:从数据集中任意挑选数据淘汰
    6、noenviction:禁止淘汰数据（默认），直接oom
    这些挑选都是随机的挑选一些数据，再利用规则淘汰
    当内存达上限的时候，redis会启动淘汰机制。redis淘汰数据时还会同步到aof中、从机

redis实现mq
  1、redis的列表键，lpush 放表头,rpop 表尾删除
  2、订阅/发布模式

strace -ff -o out /usr/java/bin/java TestOldSocket    Linux追踪java程序，输入到out开头的文件
netstat -natp  查看tpc状态，谁和谁连接了，那个端口在监听
ps -ef|grep 进程名  查看进程pid

设计模式：
  单例模式
  工厂模式
  观察者模式
  适配器模式
  装饰器模式
  代理模式
  责任链模式
  状态模式

TreeMap：基于红黑二叉树的NavigableMap的实现，线程非安全。可以对key进行排序
多线程的五大状态：
  创建状态
  就绪状态
  阻塞状态
  运行状态
  死亡状态

一致性hash
  简单hash：当节点变化的时候，所有数据都得重新hash，变动，一致性hash解决这个问题
  把hash值分布在0-2的32次方，首尾相接的圆环。
  首先求出服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
  然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
  然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台服务器上
  使用虚拟节点解决数据倾斜问题

tomcat基本结构
  1、server：只有一个，掌管着整个Tomcat的生死大权，包含多个service
  2、service：包含多个connector和一个container
  3、connector：处理连接相关的事情，并提供Socket与Request和Response相关的转化，封装好后丢给container
  4、container：封装和管理Servlet，以及具体处理Request请求。包含一个engine
  5、engine：引擎，用来管理多个站点，将传入请求委托给适当的虚拟主机处理。包含多个host
  6、host：代表一个站点，也可以叫虚拟主机。主要概念：主机的域名和根目录。包含多个context
  7、context：代表一个web应用，包含多个wrapper
  8、wrapper：代表一个servlet
  Container处理请求是使用Pipeline-Value管道(责任链模式)来处理的
tomcat优化：
  1、设置connector的协议（nio、bio、apr）tomcat 8.0默认是NIO
  2、设置connector的线程池大小，默认最大线程数是200
  3、关闭host的unpackWARs（自动解压war包）、autoDeploy（自动部署），可以节省一个线程
  4、关闭context的reloadable（热更新class），节省线程
  5、设置jvm参数，内存占用什么的

AQS（抽象的队列式同步器）原理
  1、state      标记锁的状态，获取锁的线程数。读写锁里：高16位表示读锁状态，低16位表示写锁状态
  2、双向队列   存放阻塞线程
  3、CAS        改变锁的状态、节点状态，设置头结点、尾节点
  4、自旋       被唤醒的线程会自旋，尝试获取锁
  5、保存已经获得锁的线程，实现重入

jstack用于生成java虚拟机当前时刻的线程快照
jstack -l pid > D:\jstatck.txt  把进程线程信息写入jstatck.txt文件
可以看到线程获取了哪些资源，正在等待哪些资源，从而判断哪两个线程死锁。写代码的时候给线程命名，这样就好找问题
分析工具：https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda
查找执行时间最长的线程：https://www.cnblogs.com/chengJAVA/p/5821218.html
top -H -p pid 查看进程pid的所有的线程，默认是按照%CPU高~低排序
或者直接使用top查看， shift+H显示所有的线程，默认按照%CPU高~低排序

指令重排序：
  编译器优化重排
  CPU指令重排：
   1、两条指令无相关性
   2、第一条执行时间比较长，CPU就会先执行第二条
一个Object对象占16个字节：MarkWorld（8字节）、klasspointer（4字节，指向哪个类）、对齐（4字节）。Object对象没有成员变量
对象怎么定位
 1、句柄
 2、直接地址

nexus搭建maven私有仓库
  https://www.jianshu.com/p/1cfbc1518fce
  1、hosted（宿主仓库库） ：存放本公司开发的jar包（正式版本、测试版本）
  2、proxy（代理仓库）：代理中央仓库、Apache下测试版本的jar包
  3、group（组仓库）：使用时连接组仓库，包含Hosted（宿主仓库）和Proxy（代理仓库），本地配置用这个仓库地址

Jenkins
  新建item-->选流水线-->流水线选 Pipeline script from SCM，从git上拉取脚本执行；流水线语法可以自动生成脚本代码；设置构建参数
  拉取的代码在workspace目录下
  注意：脚本里参数值要用双引号
  def git_url = "git@github.com:dxl1991/spring-boot-demo.git"
  node {
     def mvnHome
     stage('pull code') {
        checkout([$class: 'GitSCM', branches: [[name: "*/${branch}"]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: '1', url: "${git_url}"]]])
     }
     stage('Build') {
        bat label: '', script: 'mvn clean package'
     }
     stage('run') {
        bat label: '', script: 'start /min java -jar target/spring-boot-demo.jar'
     }
  }

算法练习网站：
https://www.cs.usfca.edu/~galles/visualization/Algorithms.html

32位jvm和64位jvm
  32位JDK在32位和64位的操作系统中均可运行，堆最大内存4G
  64位JDK仅能在64位的操作系统中运行，堆最大内存无限制，无法切换到Client模式
  针对32-bit VM写的代码必须重新编译才能在64-bit VM工作

https = http + SSL，可以拦截信息并查看，但是不能篡改
https步骤：
  1.客户端向服务器发起HTTPS请求，连接到服务器的443端口
  2.服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。
  3.服务器将自己的公钥发送给客户端。
  4.客户端收到服务器端的公钥之后，会对公钥进行检查，验证其合法性，如果发现公钥有问题，那么HTTPS传输就无法继续。
  严格的说，这里应该是验证服务器发送的数字证书的合法性。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，
  我们将该密钥称之为client key，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的公钥对客户端密钥进行非对称加密，
  这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束。
  5.客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。
  6.服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。
  7.然后服务器将加密后的密文发送给客户端。
  8.客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。
非对称加密算法效率比对称加密算法慢很多

正向代理代理的对象是客户端，反向代理代理的对象是服务端
keepalive + nginx 实现nginx的高可用，对外提供一个虚拟ip，然后配置主从nginx

spring boot的一次request处理
   1、FrameworkServlet 继承 HttpServlet
      doPost()
   2、DispatcherServlet 继承 FrameworkServlet
      doService() -> doDispatch()
   3、HandlerAdapter
      handle()
   4、ServletInvocableHandlerMethod 继承 HandlerMethod
      invokeAndHandle() -> invokeForRequest() -> bridgedMethod.invoke()
AbstractHandlerMethodMapping的MappingRegistry 管理者所有 HandlerMethod （path和HandlerMethod映射）
RequestMappingHandlerMapping 的 createRequestMappingInfo 判断方法是否被RequestMapping注解修饰


帧同步原理：相同的输入 + 相同的时机 = 相同的显示
           一般是以服务器按固定的帧率，来搜集每个客户端的输入，然后把这些输入广播给所有的客户端
https://www.jianshu.com/p/8cca5458c45b
https://www.jianshu.com/p/81050871cce7
    1、同步随机种子：游戏中设计随机数的使用，通过同步随机数种子可以保持随机数的一致性。
    2、客户端上传操作指令给服务器，操作指令包含游戏操作和当前帧索引。
    3、游戏广播所有客户端的操作，如果没有操作也要广播空指令来驱动游戏帧前进
    5、大概50毫秒广播一次

设计CS交互的问题：
  1、服务器发送的值和客户端收到的值不一致
      可能是字节序的问题（大小端，不同cpu不同os，字节序可能不同）
  2、服务器下发的小包数据，客户端常常延迟收到
      nagle算法导致小包延迟发送，禁用nagle算法就好了(TCP_NODELAY)
      TCP_QUICKACK关闭延迟确认机制
  3、实时交互中，数据量较大或者网络波动较大，容易发送失败
      网络传输速度较慢，发送发送缓冲区满
      适当加大发送缓冲区
QQ 一般情况下用udp连接
    网络状况差用tcp连接
微信 前台运行用TCP长连接
      后台运行用TCP短连接

protobuf编码方式：
  Varints：使用1到5个字节，数字越小，占用的字节越少，不利于处理大数和负数
  ZigZag：将有符号整数转换为无符号整数，进而能够使用Varints编码

