Synchronize语义规范：
  1、进入同步块前，先清空工作内存中的共享变量，从主内存中重新加载（也能实现变量的可见性）
  2、解锁前必须把修改的共享变量同步回主内存
volatile语义规范：
  1、使用volatile变量时，必须重新从主内存加载，并且read、load是连续的
  2、修改volatile变量后，必须立马同步回主内存，并且store、write是连续的

-------------------JVM运行时数据区-------------------
一、线程共享部分
  1、方法区
     存储加载的类信息、常量、静态变量、JIT编译后端代码数据
  2、堆内存
     存放对象实例，几乎所有对象、数组都放这里
     回收判断：引用计数器法、可达性分析算法
     默认比例：老年代占2/3，新时代占1/3（Eden占8/10，s0占1/10，s1占1/10）
     JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。
     因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间
二、线程独占部分
  1、虚拟机栈
     线程中方法执行的模型，每个方法执行时，就会在虚拟机中创建一个栈帧，每个方法从调用到执行的过程，就对应着栈帧在虚拟机中从入栈到出栈的过程
     栈帧包括：局部变量表（存放局部变量基础类型值），局部对象的引用，操作数栈（存放临时变量），返回值地址
  2、本地方法栈
     和虚拟机栈类似，虚拟机栈是为执行java方法而准备的。本地方法栈是为虚拟机使用native方法而准备的
  3、程序计数器
     记录cpu执行到字节码指令的位置，线程切换需要

直接内存：JVM之外的内存，开发人员自己分配和回收内存
使用堆外内存的原因：
1、对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内存规模，从而在GC时减少回收停顿对于应用的影响
2、提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。
DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛，DirectByteBuffer是通过虚引用(Phantom Reference)来实现堆外内存的释放的
如果禁用掉System.gc的话就可能造成堆外内存泄露，因为 为DirectByteBuffer分配空间过程中会显式调用 System.gc ，希望通过 Full GC 来强迫已经无用的 DirectByteBuffer 对象释放掉它们关联的 Native Memory

Lock和synchronized的选择
  1、Lock是接口，而synchronized是java中的关键字
  2、synchronized会自动释放锁，而Lock需要手动释放锁
  3、Lock可以让等待锁的线程响应中断，而synchronized却不行
  4、通过Lock可以知道有没有成功获得锁，而synchronized却无法办到
  5、Lock可以提供多个线程进行读操作
  6、当竞争资源非常激烈时，Lock的性能要远远大于synchronized

自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环（减少了上下文切换）

synchronized的锁升级:
  对象头里保存了锁的状态：无锁、偏向锁、轻量级锁、重量级锁。锁只能升级不能降级
  1、偏向锁：默认这个锁属于A，当A再次拿锁就直接给他，B来拿锁，发现是偏向A的，就去尝试获取锁，成功了就偏向B，否则升级为轻量级锁。用CAS设置偏向锁
  2、轻量级锁：A获取了锁，B来拿锁，先自旋一段时间，如果自旋完还没拿到锁就升级到重量级锁，B阻塞
  3、重量级锁：A获取了锁，B来拿锁，没拿到就直接阻塞了

分布式锁实现的几种方案
  1、数据库实现（乐观锁）
  2、基于zookeeper实现（创建临时顺序节点，监听前一个节点）适用于高可靠（高可用）而并发量不是太大的场景。
  3、基于redis实现。redis调用lua脚本，原子操作设置key和超时时间。推荐redission包，redis官方jar包，适用于并发量很大、性能要求很高的、而可靠性问题可以通过其他方案去弥补的场景。

常用的数据库优化方法：
  1、建索引
  2、分区表

索引的原理：
  对列值创建排序存储，数据结构={列值、行地址}。在有序的数据列表中就可以利用二分查找快速找到要查找的行地址，在根据地址直接取行数据
  mysql使用B+树存储索引

唯一id生成方法：
  1、UUID
  2、数据库自增，分库分表的时候可以设置不同表的起始值和步长不同达到全局唯一的效果
  3、雪花算法 snowflake（最高位为0+41位时间戳+10位机器id+12位一毫秒内并发数）
     优点：高性能高可用：生成时不依赖于数据库，完全在内存中生成
          容量大：每秒中能生成数百万的自增ID
          ID自增：存入数据库中，索引效率高
     缺点：依赖与系统时间的一致性，如果系统时间被回调，或者改变，可能会造成id冲突或者重复
  4、redis
  5、AtomicInteger

弱引用--WeekReference
  当一个对象仅仅被weak reference指向, 而没有任何其他strong reference指向的时候, 如果GC运行, 那么这个对象就会被回收

软引用--SoftReference
  用法和弱引用一样，回收的时候再加一个条件：内存不足的时候才会回收

虚引用--PhantomReference
  虚引用主要用来跟踪对象被垃圾回收器回收的活动。
  虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。
  当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之 关联的引用队列中。
  你声明虚引用的时候是要传入一个queue的。当你的虚引用所引用的对象已经执行完finalize函数的时候，就会把对象加到queue里面

GC roots
  1、通过System Class Loader或者Boot Class Loader加载的class对象
  2、线程栈变量
  3、静态变量
  4、常量池
  5、jni指针
  6、正在被用于同步的各种锁对象
GC 算法
  1、标记清除
  2、复制
  3、标记整理
永久代和元空间区别：
  1、永久代必须指定大小，元空间默认无上限
  2、字符串常量1.7放永久代，1.8后放在堆里
  3、元空间由操作系统管理
jvm GC
  Minor GC：清理新生代，Eden区满了会触发一次（把根引用对象复制到s0或者s1区域，并且把对象的分代年龄+1，分带年龄大于15的对象会进入到老年代。可回收对象就直接清理掉）
  Major GC：Full GC
  Full GC：清理整个堆，包括新生代和老年代
  https://www.cnblogs.com/yuyutianxia/p/8986902.html
  shallow heap：这个对象实际占用的堆大小（ 类定义引用大小 + 父类的成员变量所占的空间 + 当前类的成员变量所占的空间 + 结构体对齐）
  retained heap：如果这个对象被删除了（GC回收掉），能节省出多少内存
  -XX:SurvivorRatio=6 ，设置的是Eden区与每一个Survivor区的比值，可以反推出占新生代的比值，Eden为6, 两个Survivor为2, Eden占新生代的3/4, 每个Survivor占1/8，两个占1/4

Full GC触发条件：
  1、System.gc()方法的调用。此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定，但很多情况下它会触发 Full GC
  2、老年代空间不足。新生代对象转入 或者 创建为大对象、大数组时 发现老年代空间不足
  3、方法区空间不足。CMS GC可避免这个问题
  4、判断当前新生代的对象是否能够全部顺利的晋升到老年代，如果不能，就提早触发一次老年代的收集
  5、CMS GC时出现promotion failed和concurrent mode failure时：进行Minor GC时，survivor space放不下, 对象只能放入老年代，而此时老年代也放不下

如何减少Full GC次数：
  1、尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间（加大新生代的空间，降低Minor GC的频率）
  2、不要创建过大的对象及数组（因为数组需要连续空间）
  3、CMS模式里，Full GC之后额外免费赠送一个碎片整理的过程。XX:+UseCMSCompactAtFullCollection（默认开启的）
     执行多少次不压缩的Full GC后,跟着来一次带压缩的。-XX:CMSFullGCsBeforeCompaction （默认值为0，表示每次Full GC是都进行碎片整理），可降低STW的时间
  4、禁止使用System.gc()方法

CMS收集器：
  过程：初始标记、并发标记、重新标记、并发清除
  缺点：1、对CPU资源敏感。默认启动回收线程数=(CPU数量+3)/4，CPU小于4个的时候，对CPU资源占用较大
        2、无法处理浮动垃圾，并发清除阶段，用户线程会产生新的垃圾，CMS只能下次回收
  -XX:CMSInitiatingOccupancyFraction = 92 ：当老年代内存使用了92%就启用CMS收集。这个值如果设置的太大，那么导致并发清除的时候，预留给用户线程的内存不够，
     会出现Concurrent Mode Failure失败。这时候jvm会启动Serial Old收集器来重新收集老年代，这样停顿的时间就长了

G1（Garbage First）收集器：
  开启选项：-XX:+UseG1GC
  使用copy算法
  化整为零的思路：将java堆划分为多个大小相等的独立区域（Region）
  可停顿的预测：使用者可以明确指定在M毫秒的时间片段内，GC不超过N毫秒
  维护一个优先级列表，优先回收价值最大的Region
  运作期间不会产生内存空间碎片，收集后能提供连续的可用内存
  过程：初始标记、并发标记、最终标记、筛选回收

ZGC（The Z Garbage Collector）
  JDK 11中推出的一款低延迟垃圾回收器
      停顿时间不超过10ms；
      停顿时间不会随着堆的大小，或者活跃对象的大小而增加；
      支持8MB~4TB级别的堆（未来支持16TB）。
  与CMS中的ParNew和G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因
  ZGC只有三个STW阶段：初始标记，再标记，初始转移
  ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移.

问题：当磁盘IO压力很大时，JVM可能被阻塞一段较长的时间，导致gc时间很长
    1、JVM GC需要通过发起系统调用write()，来记录GC行为。
    2、write()调用可以被后台磁盘IO所阻塞。
    3、记录GC日志属于JVM停顿的一部分，因此write()调用的时间也会被计算在JVM STW的停顿时间内。
解决：GC日志文件放到单独的HDD或者高性能磁盘（例如SSD）上，来避免IO竞争。

jvm参数分类：
  1、-开头，标准参数，所有HotSpot都支持
  2、-X开头，非标准参数，默认jvm实现这些参数的功能，但是并不保证所有jvm实现都满足，且不保证向后兼容
  3、-XX开头，非Stable参数，下个版本可能取消

查看对象个数：jmap -histo:live pid | more
dump内存：jmap -dump:file=a.dump pid
查看堆概要：jmap -heap pid

netty两个线程池作用
  一个负责接受客户端的TCP连接
  一个负责处理I/O相关的读写操作，或执行系统task、定时task。一个线程对应多个链路，一个链路对应一个线程，避免并发
特定Hotspot版本支持
redis慢查询日志：
  slowlog-log-slower-than：慢查询预定阀值
  slowlog-max-len:先进先出队列的长度，超过长度后新日志进入会删除老日志（所以可以定期用slowlog get命令获取日志并保持到mysql里）
  慢查询日志记录的是命令执行时间超过阀值的命令，客户端命令执行时间 = 排队等待时间 + 执行时间 + 网络传输时间
  当客户端命令执行时间过长，排查过程：如果慢查询日志里没有，用redis监控看连接数是否大于最大连接数，看是否RDB占用了很多时间

类加载过程：
  加载-->验证-->准备-->解析-->初始化
  内部类只有在使用的时候才会被加载，可利用这一特性写单例模式（避免过早初始化的问题）
  枚举不能被反射创建

aop 应用场景：日志，事务，权限,参数校验
    实现原理是动态代理
    spring的AOP实现
    1、jdk动态代理
    2、采用Cglib动态代理可以对没有实现接口的类产生代理，实际上是生成了目标类的子类来增强。
mybatis的Mapper使用了动态代理创建Dao
静态代理模式：
   接口
   被代理类：实现接口
   代理类：实现接口 + 引用真实类
   这样代理就可以对外提供接口的所有方法（可选择用被代理类实现，或自己实现这些方法）
动态代理模式：
   反射方式实现，避免实现所有接口的所有方法(jdk动态帮我们创建一个类(字节码文件),以$Proxy开头)
   代理类的调用方法
   invoke（Method method）{
      if(method 是需要我自己实现的){
         我就自己实现
         return
      }
      //被代理类去实现
      method.invoke()
   }


class文件的开头是一个魔数：0xCAFEBABE
mybatis分页插件

线程池执行任务流程：
   1 使用核心线程执行(优先使用空闲线程，没有再创建线程)
   2 核心线程数满了，放入队列
   3 队列满了，使用临时线程
   4 临时线程数满了，使用拒绝策略

ScheduledThreadPoolExecutor原理
   1.任务都封装到 ScheduledFutureTask 里面，并加入队列。run方法执行完毕后，如果是周期任务就把此任务再次加入队列
   2.采用延迟阻塞队列 DelayedWorkQueue ，通过任务延迟时间排序。线程自旋拿任务，判断队首元素的执行时间是否到达，没到就阻塞直到延迟时间到达

   scheduleWithFixedDelay ：无论任务执行是否大于间隔时间，都会休息一个间隔时间再执行下一个任务。即一定会给cpu休息时间
   scheduleAtFixedRate ：如果任务执行时间大于间隔时间，则会立即执行下一个任务。休息间隔=max(0,间隔时间 - 任务执行时间)
   注意：两个方法都不会出现两个任务同时执行的情况

上下文切换带来的损耗
   1、CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉
   2、多核的cache之间得共享数据
   https://www.jianshu.com/p/5549e89133d2

线程池大小设置：
    cpu密集型：cup核心数 + 1 （cpu的利用率高，不用开太多的线程，开太多线程反而会因为线程切换时切换上下文而浪费资源）
    io密集型：cup核心数 * 2 （因为IO操作会阻塞线程，cpu利用率不高，可以开多点线程，阻塞时可以切换到其他就绪线程，提高cpu利用率）
    实际应用：cup核心数 *（1 + 线程等待时间 / 线程运行时间）

御龙在天线程模型：
    玩家线程：一个队列，一个（单线程）线程池，多个玩家共用一个队列。总共CPU核数 * 2个队列
    db线程池：CPU核数 * 2
    定时器线程池：CPU核数 * 2
    场景线程：CPU核数 * 2。用来100毫秒刷新一次场景，同一个场景同一时刻只有一个线程执行
              两个定时器用同一个线程池执行任务：一个定时器刷新玩家视野；一个定时器刷新怪物状态，ai，复活，产生新的怪物，执行延迟技能
              刷新视野：遍历地图对象，如果有位置变化，把自己更新到周围格子；玩家视野边长范围2-6格子；每个格子记录可以看到这个格子的玩家
TCP三次握手：
   可以理解为应该4次握手合并成了三次，每个端都需要一问一答才能确立连接。
   c问s答，c确认建立连接；s问c答，s确认建立连接。syn是问，ack是答
   但是服务器把答（ack）和问（syn）一次性发送过去了。
   第三次握手是为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误。
TCP四次挥手：
   每个端都需要一问一答才能确认关闭 。请求关闭（FIN），回答（ACK）
   为什么不是三次？
   因为服务器的问答不能合并发送了
   因为服务端接到客户端关闭请求后，自己可能还有消息要处理，所以不能立马告诉客户端我要关闭，要等消息处理完再发送关闭请求。
   服务器比客户端先关闭连接，因为客户端发送最后一个ack后，会启动一个计时器。计时器到了，才关闭连接。而服务器接收到ack就立马close。这么做是防止最后一个ack丢失
TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。
服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。
若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接

TCP保证可靠性：
  1、确认机制：每个段都有序列号（前一个段的序号+字节长度），收到段后返回确认号（收到段的序号+字节长度），若确认号为= N，则表明：到序号N-1为止的所有数据都已正确收到
  2、重传机制：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。定时器的时间是动态计算的
  3、滑动窗口：TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出(不用等ack，可以连续发送多个包)
               接收端处理数据的速度是有限的. 如果发送端发的太快, 导致接收端的缓冲区被打满, 这个时候如果发送端继续发送, 就会造成丢包, 继而引起丢包重传等等一系列连锁反应.
  在网络不好的情况下，tcp的延时会加重，重传时间变的更长

UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。简单来说，当一台计算机向另外一台计算机发送数据时，发送端不会确认接收端是否存在，就会发出数据，同样接收端在收到数据时，也不会向发送端反馈是否收到数据。
由于使用UDP协议消耗资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输例如视频会议都使用UDP协议，因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。
但是在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议。
UDP传输数据被限制在64K以内,在内网传输，最好控制在1472字节(1500-8-20),在内网传输，最好控制在1472字节(1500-8-20)

Snappy压缩库
Snappy是Google开源的压缩/解压缩库。和其他压缩库相比，snappy的压缩率并不是最高的，兼容性也并非最好的。相反，它的诞生旨在以极高的压缩/解压缩速率提供合理的压缩率。
Snappy官指出：在64位单核core-i7处理器下，snappy的压缩率能够达到250MB/S，而解压缩速度则能达到500MB/S。
目前很多软件使用（或支持）snappy作为压缩库，如MongoDB,Cassandra,Hadoop,Lucene

迭代器
  一种设计模式
  不同集合的内部数据结构不一样，遍历方式也不一样。利用迭代器统一实现遍历，不同集合内部实现方式不一样，但是对外使用都是一样的。
  Iterable 接口提供获取Iterator方法，并且实现这个接口可以用foreach遍历
  Iterator 提供遍历的方法

clone
  Object的clone方法是native方法，是protected，只有子类能调用
  子类只有实现了Cloneable接口才能调用Object的clone()方法，否则报错
  Object的clone()方法会创建一个新对象，对象的成员变量和老的对象一样，包括基础类型和引用类型

java使用Unicode编码：Unicode编码则是采用双字节16位来进行编号，可编65536字符，是全世界一种通用的编码

线程安全的list
  1、CopyOnWriteArrayList 当读远大于写的时候使用
  2、Collections.synchronizedList(new ArrayList<>())
  3、Vector
    Vector，它是ArrayList的线程安全版本，其实现90%和ArrayList都完全一样，区别在于：
    1、Vector是线程安全的，ArrayList是线程非安全的
    2、Vector可以指定增长因子，如果该增长因子指定了，那么扩容的时候会每次新的数组大小会在原数组的大小基础上加上增长因子；
       如果不指定增长因子，那么就给原数组大小*2
线程安全的map
  1、HashTable
  2、Collections.synchronizedMap(new HashMap<>())
  3、ConcurrentHashMap
线程安全的queue
  1、ConcurrentLinkedQueue  全程采用cas，无锁操作，避免线程的上下文切换。无法设置队列大小
  2、ArrayBlockingQueue   put 和 get 用同一个 ReenterLock。Condition实现阻塞，唤醒。不会封装Node节点，减少对象的创建。必须设置大小
  3、LinkedBlockingQueue  put 和 get 锁分离。Condition实现阻塞，唤醒。可以设置队列大小
  4、SynchronousQueue     put一定阻塞，有人拿走了我的消息，我就被唤醒
  5、LinkedTransferQueue  融合了ConcurrentLinkedQueue、LinkedBlockingQueue、SynchronousQueue（公平模式）
  6、PriorityBlockingQueue 按优先级出队（元素实现Comparable，或者指定Comparator）
  7、DelayQueue  队列里用了PriorityQueue存数据，所以是有序出队，每个元素还有一个延时时间，到了延时时间才能出队
  8、Disruptor框架：是由LMAX公司开发的一款高效的无锁内存队列
  https://www.jianshu.com/p/ae6977886cec

缓存穿透：请求数据，在redis里没找到，然后到数据库去查找也没找到，这个就叫穿透。用户可以用很多无效id请求攻击服务器，占用数据库资源。
解决方案：布隆过滤器，将id用多个hash算法计算出多个指纹，将指纹放入bitmap里。如果布隆过滤器说没有那就一定没有，说有那就可能有。
          布隆过滤器可用于海量数据里判断出某个数据是否存在
缓存击穿：当缓存key失效的瞬间，大量请求访问key，造成数据库压力过大
解决方案：设置互斥锁，当缓存不存在，尝试去获取锁，获取到锁了去数据库加载并设置到缓存；没有获取到锁就休眠一会再获取数据

缓存雪崩：大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩
解决方案：可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效

redis数据淘汰策略
    1、volatile-lru:从已设置过期的数据集中挑选最近最少使用的淘汰
    2、volatile-ttr:从已设置过期的数据集中挑选将要过期的数据淘汰
    3、volatile-random:从已设置过期的数据集中任意挑选数据淘汰
    4、allkeys-lru:从数据集中挑选最近最少使用的数据淘汰
    5、allkeys-random:从数据集中任意挑选数据淘汰
    6、noenviction:禁止淘汰数据（默认），直接oom
    这些挑选都是随机的挑选一些数据，再利用规则淘汰
    当内存达上限的时候，redis会启动淘汰机制。redis淘汰数据时还会同步到aof中、从机

redis实现mq
  1、redis的列表键，lpush 放表头,rpop 表尾删除
  2、订阅/发布模式

redis命令：INCR key 试key值自增

strace -ff -o out /usr/java/bin/java TestOldSocket    Linux追踪java程序，输入到out开头的文件
netstat -natp  查看tpc状态，谁和谁连接了，那个端口在监听
ps -ef|grep 进程名  查看进程pid

设计模式：
  单例模式
  工厂模式
  观察者模式
  适配器模式
  装饰器模式
  代理模式
  责任链模式
  状态模式

TreeMap：基于红黑二叉树的NavigableMap的实现，线程非安全。可以对key进行排序
多线程的五大状态：
  创建状态
  就绪状态
  阻塞状态
  运行状态
  死亡状态

一致性hash
  简单hash：当节点变化的时候，所有数据都得重新hash，变动，一致性hash解决这个问题
  把hash值分布在0-2的32次方，首尾相接的圆环。
  首先求出服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
  然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
  然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台服务器上
  使用虚拟节点解决数据倾斜问题

tomcat基本结构
  1、server：只有一个，掌管着整个Tomcat的生死大权，包含多个service
  2、service：包含多个connector和一个container
  3、connector：处理连接相关的事情，并提供Socket与Request和Response相关的转化，封装好后丢给container
  4、container：封装和管理Servlet，以及具体处理Request请求。包含一个engine
  5、engine：引擎，用来管理多个站点，将传入请求委托给适当的虚拟主机处理。包含多个host
  6、host：代表一个站点，也可以叫虚拟主机。主要概念：主机的域名和根目录。包含多个context
  7、context：代表一个web应用，包含多个wrapper
  8、wrapper：代表一个servlet
  Container处理请求是使用Pipeline-Value管道(责任链模式)来处理的
tomcat优化：
  1、设置connector的协议（nio、bio、apr）tomcat 8.0默认是NIO
  2、设置connector的线程池大小，默认最大线程数是200
  3、关闭host的unpackWARs（自动解压war包）、autoDeploy（自动部署），可以节省一个线程
  4、关闭context的reloadable（热更新class），节省线程
  5、设置jvm参数，内存占用什么的

AQS（抽象的队列式同步器）原理
  1、state      标记锁的状态，获取锁的线程数。读写锁里：高16位表示读锁状态，低16位表示写锁状态
  2、双向队列   存放阻塞线程
  3、CAS        改变锁的状态、节点状态，设置头结点、尾节点
  4、自旋       被唤醒的线程会自旋，尝试获取锁
  5、保存已经获得锁的线程，实现重入

jstack用于生成java虚拟机当前时刻的线程快照
jstack -l pid > D:\jstatck.txt  把进程线程信息写入jstatck.txt文件
可以看到线程获取了哪些资源，正在等待哪些资源，从而判断哪两个线程死锁。写代码的时候给线程命名，这样就好找问题
分析工具：https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda
查找执行时间最长的线程：https://www.cnblogs.com/chengJAVA/p/5821218.html
top -H -p pid 查看进程pid的所有的线程，默认是按照%CPU高~低排序
或者直接使用top查看， shift+H显示所有的线程，默认按照%CPU高~低排序

指令重排序：
  编译器优化重排
  CPU指令重排：
   1、两条指令无相关性
   2、第一条执行时间比较长，CPU就会先执行第二条
一个Object对象占16个字节：MarkWorld（8字节）、klasspointer（4字节，指向哪个类）、对齐（4字节）。Object对象没有成员变量
对象怎么定位
 1、句柄
 2、直接地址




Jenkins
  新建item-->选流水线-->流水线选 Pipeline script from SCM，从git上拉取脚本执行；流水线语法可以自动生成脚本代码；设置构建参数（需安装插件Extended Choice Parameter Plug-In）
  拉取的代码在workspace目录下
  注意：脚本里参数值要用双引号
  示例1：
  def git_url = "git@github.com:dxl1991/spring-boot-demo.git"
  node {
     def mvnHome
     stage('pull code') {
        checkout([$class: 'GitSCM', branches: [[name: "*/${branch}"]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: '1', url: "${git_url}"]]])
     }
     stage('Build') {
        bat label: '', script: 'mvn clean package'
     }
     stage('run') {
        bat label: '', script: 'start /min java -jar target/spring-boot-demo.jar'
     }
  }
  示例2：
  node {
     stage('Update') {
        echo "code branch:${branch}"
        checkout([$class: 'GitSCM', branches: [[name: "*/${branch}"]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], userRemoteConfigs: [[url: 'git@gitlab.dianchu.cc:20200135/ssjfserver.git']]])
     }
     stage('Build') {
        sh label: '', script: 'mvn -Dmaven.test.failure.ignore clean package'
     }
     stage('Run') {
        withEnv(['JENKINS_NODE_COOKIE=background_job']) {
          sh label: '', script: '/game/deploy-pipeline.sh'
  		sh label: '', script: '/game/check.sh'
  	  }
     }
  }

算法练习网站：
https://www.cs.usfca.edu/~galles/visualization/Algorithms.html

32位jvm和64位jvm
  32位JDK在32位和64位的操作系统中均可运行，堆最大内存4G
  64位JDK仅能在64位的操作系统中运行，堆最大内存无限制，无法切换到Client模式
  针对32-bit VM写的代码必须重新编译才能在64-bit VM工作

https = http + SSL，可以拦截信息并查看，但是不能篡改
https步骤：
  1.客户端向服务器发起HTTPS请求，连接到服务器的443端口
  2.服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。
  3.服务器将自己的公钥发送给客户端。
  4.客户端收到服务器端的公钥之后，会对公钥进行检查，验证其合法性，如果发现公钥有问题，那么HTTPS传输就无法继续。
  严格的说，这里应该是验证服务器发送的数字证书的合法性。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，
  我们将该密钥称之为client key，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的公钥对客户端密钥进行非对称加密，
  这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束。
  5.客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。
  6.服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。
  7.然后服务器将加密后的密文发送给客户端。
  8.客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。
非对称加密算法效率比对称加密算法慢很多
对称加密算法：
  DES（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。
  3DES（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。
  AES（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别高
非对称加密算法：
  RSA：由 RSA 公司发明，是一个支持变长密钥的公共密钥算法，需要加密的文件块的长度也是可变的；
  DSA（Digital Signature Algorithm）：数字签名算法，是一种标准的 DSS（数字签名标准）；
  ECC（Elliptic Curves Cryptography）：椭圆曲线密码编码学。

正向代理代理的对象是客户端，反向代理代理的对象是服务端
keepalive + nginx 实现nginx的高可用，对外提供一个虚拟ip，然后配置主从nginx

nginx 分多个配置文件：
只需要在原来文件/etc/nginx/nginx.conf 的http 块下加一句话就可以了:
include /etc/nginx/conf.d/*.conf;

spring boot的一次request处理
   1、FrameworkServlet 继承 HttpServlet
      doPost()
   2、DispatcherServlet 继承 FrameworkServlet
      doService() -> doDispatch()
   3、HandlerAdapter
      handle()
   4、ServletInvocableHandlerMethod 继承 HandlerMethod
      invokeAndHandle() -> invokeForRequest() -> bridgedMethod.invoke()
AbstractHandlerMethodMapping的MappingRegistry 管理者所有 HandlerMethod （path和HandlerMethod映射）
RequestMappingHandlerMapping 的 createRequestMappingInfo 判断方法是否被RequestMapping注解修饰


帧同步原理：相同的输入 + 相同的时机 = 相同的显示
           一般是以服务器按固定的帧率，来搜集每个客户端的输入，然后把这些输入广播给所有的客户端
https://www.jianshu.com/p/8cca5458c45b
https://www.jianshu.com/p/81050871cce7
    1、同步随机种子：游戏中设计随机数的使用，通过同步随机数种子可以保持随机数的一致性。
    2、客户端上传操作指令给服务器，操作指令包含游戏操作和当前帧索引。
    3、游戏广播所有客户端的操作，如果没有操作也要广播空指令来驱动游戏帧前进
    5、大概50毫秒广播一次

设计CS交互的问题：
  1、服务器发送的值和客户端收到的值不一致
      可能是字节序的问题（大小端，不同cpu不同os，字节序可能不同）
  2、服务器下发的小包数据，客户端常常延迟收到
      nagle算法导致小包延迟发送，禁用nagle算法就好了(TCP_NODELAY)
      TCP_QUICKACK关闭延迟确认机制
  3、实时交互中，数据量较大或者网络波动较大，容易发送失败
      网络传输速度较慢，发送发送缓冲区满
      适当加大发送缓冲区
QQ 一般情况下用udp连接
    网络状况差用tcp连接
微信 前台运行用TCP长连接
      后台运行用TCP短连接

protobuf编码方式：
  Varints：使用1到5个字节，数字越小，占用的字节越少，不利于处理大数和负数。
    1.对一个无符号整数，将其换算成二进制
    2.从右往左取7位,然后在最高位补1
    3.一直继续，直到取到最后一个有意义的字节(在最后一个有意义的字节上最高位补0)
    4.先取到的字节排在后取到的字节前面，得到一个新的字节，转换成十进制就是压缩的结果
  ZigZag：将有符号整数转换为无符号整数，进而能够使用Varints编码

git换行符问题，文件一致却提示有修改
解决方法：
git config --global core.autocrlf false  #提交检出均不转换
git config --global core.safecrlf true   #拒绝提交包含混合换行符的文件
check out代码时，换行符会自动由LF转换为CRLF，而在commit时，Git也会将CRLF转换为LF，以方便在Windows上开发

linux root 目录下没有.ssh目录
解决办法：ssh localhost

生成对称秘钥：ssh-keygen -t rsa -C "249083650@qq.com"  //-C指定注释， -t指定秘钥类型，默认生成用于SSH-2的RSA密钥
将公钥追加到 /root/.ssh/authorized_keys文件中 即可让远程主机免密登陆

.git/HEAD 当前工作区域的指针，一般指向当前分支
.git/refs/heads 是个文件夹，包含本地分支列表
git checkout dca15df  可以从某个提交记录检出，此时HEAD指向这个提交记录，处于一个临时分支
git checkout -b 分支名 创建一个分支并切换过去
git branch 分支名 dca15df 从某个提交记录创建一个新分支
git branch -D 分支名 强行删除一个未合并的分支
git rebase -i dca15df(或者 HEAD~2) 将几次提交合并成一次提交
git push origin master:master  前一个master本地的master，后一个master远端master。如果两个分支相同，可以都省略
git pull origin master:master  前一个master远端的master，后一个master本地master。如果后面的master省略，则表示合入本地当前分支
git merge 分支名  把分支合并到当前分支
git merge --abort 出现冲突后，放弃这次合并，还原到合并之前的状态
git merge --continue 解决完冲突后继续完成合并
git reset --hard dca15df 回退到某一次提交  ，再用git push -f 强推到远端
git checkout .  撤销对所有已修改但未提交的文件的修改，但不包括新增的文件
git checkout [filename]    撤销对指定文件的修改，[filename]为文件名
git cherry-pick 82ecb31 在当前分支合并82ecb31记录（git不同分支的每一次提交id都是唯一，所以可以用这个方法合并其他分支的某一次提交到当前分支）
git revert 82ecb31 还原某一次提交，风险很大，很容易冲突，常用来还原最近的一次本地提交

zookeeper分布式锁：
   1、创建父节点（容器节点lock）
   2、创建临时顺序节点 create -s -e /lock/seq
   3、如果自己是顺序id最小节点则获得锁，否则监听比我小1的id节点
   4、如果我监听的节点变化，我再获取节点列表，如果我最小，我就获得了锁
   5、删除我的顺序节点，释放锁
Curator有封装好的

systemctl 提供了一组子命令来管理单个的 unit，其命令格式为：
systemctl [command] [unit]
command 主要有：
    start：立刻启动后面接的 unit。
    stop：立刻关闭后面接的 unit。
    restart：立刻关闭后启动后面接的 unit，亦即执行 stop 再 start 的意思。
    reload：不关闭 unit 的情况下，重新载入配置文件，让设置生效。
    enable：设置下次开机时，后面接的 unit 会被启动。
    disable：设置下次开机时，后面接的 unit 不会被启动。
    status：目前后面接的这个 unit 的状态，会列出有没有正在执行、开机时是否启动等信息。
    is-active：目前有没有正在运行中。
    is-enable：开机时有没有默认要启用这个 unit。
    kill ：不要被 kill 这个名字吓着了，它其实是向运行 unit 的进程发送信号。
    show：列出 unit 的配置。
    mask：注销 unit，注销后你就无法启动这个 unit 了。
    unmask：取消对 unit 的注销。

关闭防火墙：
systemctl stop firewalld.service && systemctl disable firewalld.service

elasticsearch启动：
systemctl start elasticsearch
systemctl stop elasticsearch

elasticsearch head插件启动
cd /usr/local/src/elasticsearch-head
npm run start &
或者启动脚本
sh /usr/bin/elasticsearch-head start

kibana启动
systemctl start kibana
systemctl enable kibana
ss -nltpd  |grep 5601

logstash启动
systemctl restart logstash
检测配置文件是否有语法错误
/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/ssjf-log.conf -t


配置路径：
/etc/elasticsearch/elasticsearch.yml
/etc/logstash/conf.d/
/etc/logstash/logstash.yml

nginx
nginx -c /etc/nginx/nginx.conf
nginx -s stop
nginx -s reload

设置开机启动
编写脚本 /etc/init.d/logstash
        #!/bin/sh
        case $1 in
                start) systemctl start logstash;;
                stop) systemctl stop logstash;;
                restart) systemctl restart logstash;;
                *) echo "require start|stop|restart" ;;
        esac
然后可以用 service logstash start 就可以启动


shell编程是以"#"为注释，但对"#!/bin/sh"却不是。"#!/bin/sh"是对shell的声明
#!/bin/sh 是指此脚本使用/bin/sh来解释执行，#!是特殊的表示符，其后面跟的是解释此脚本的shell的路径
Shebang：#! 后面跟解释器的绝对路径，用于指明执行这个脚本文件的解释器，例如：以指令#/bin/cat开头的文件aaa,如果以./aaa执行就会调用cat输出文件内容
要求：
    #! 必须连接在一起
    #! 必须在文件的最开始，第一行
    # 开头的语句一般情况下会被当成注释而忽略，所以Shebang 对文件的内容是没有影响的
    #! 开头的一行会设置解释器运行环境


协程是基于线程的。内部实现上，维护了一组数据结构和 n 个线程，真正的执行还是线程，协程执行的代码被扔进一个待执行队列中，由这 n 个线程从队列中拉出来执行
1. 内存消耗方面
　　　　每个 goroutine (协程) 默认占用内存远比 Java 、C 的线程少。
　　　　goroutine：2KB
　　　　线程：8MB
2. 线程和 goroutine 切换调度开销方面
　　　　线程/goroutine 切换开销方面，goroutine 远比线程小
　　　　线程：涉及模式切换(从用户态切换到内核态)、16个寄存器、PC、SP...等寄存器的刷新等。
　　　　goroutine：只有三个寄存器的值修改 - PC / SP / DX.

ByteBuf介绍：
  分类：
     1、是否池化
     PooledByteBuf  缓存池
     UnPooledByteBuf  非缓存池
     2、存储地址
     HeapByteBuf 堆内存（初始化快，但是推送网络io需要一次拷贝）
     DirectByteBuf 直接内存（初始化慢，但是推送网络io零拷贝）

  优势：
    1、可变长
    2、可池化（引用计数）
    3、可实现零拷贝
    4、读写双索引
    5、灵活读写数据结构（可调整索引位置）

Netty 的 Encode、Decoder
  1、MessageToByteEncoder<Message> or ByteToMessageDecoder<Message>  将对象变为字节流 or 将字节流变为对象
  2、MessageToMessageEncoder<Message> or MessageToMessageDecoder<Message> 将对象变为对象
  3、ByteToMessageCodec<Message> or MessageToMessageCodec<Decode_Message,Encode_Message> encode和decode在一个类里

Netty的对拆包粘包问题的处理
  1、消息定长 FieldLengthFrameDecoder / FieldLengthFrameEncoder
  2、消息末尾加分隔符
     LineBasedFrameDecoder 以换行符结尾
     DelimiterBasedFrameDecoder 自定义结尾标记
  3、消息添加长度字段
     LengthFieldPrepender 在encode过程中，在消息前加长度字段
     LengthFieldBasedFrameDecoder 在index开始读length字段作为长度，然后读取长度字节

一、yum安装
  定义：yum（ Yellow dog Updater, Modified）是一个在 Fedora 和 RedHat 以及 SUSE 中的 Shell 前端软件包管理器，自动解决依赖关系
       yum 也可以安装rpm软件包，如：rpm -ivh wps-office-10.1.0.5672-1.a21.x86_64.rpm
  语法：yum [options] [command] [package ...]
       options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为 "yes"），-q（不显示安装的过程）等等。
       command：要进行的操作。
       package：安装的包名。
  常用命令：
      1. 列出所有可更新的软件清单命令：yum check-update
      2. 更新所有软件命令：yum update
      3. 仅安装指定的软件命令：yum install <package_name>
      4. 仅更新指定的软件命令：yum update <package_name>
      5. 列出所有可安裝的软件清单命令：yum list
      6. 删除软件包命令：yum remove <package_name>
      7. 查找软件包命令：yum search <keyword>
      8. 清除缓存命令:whic
          yum clean packages: 清除缓存目录下的软件包
          yum clean headers: 清除缓存目录下的 headers
          yum clean oldheaders: 清除缓存目录下旧的 headers
          yum clean, yum clean all (= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的 headers

二、rpm安装
  rpm 用来安装已下载好的.rpm文件。但是RPM无法解决软件包的依赖关系。
    1.安装软件：执行rpm -ivh rpm包名，如：rpm -ivh apache-1.3.6.i386.rpm
    2.升级软件：执行rpm -Uvh rpm包名。
    3.卸载：执行rpm -e rpm包名。
    4.查询软件包的详细信息：执行rpm -qpi rpm包名
    5.查询某个文件是属于那个rpm包的：执行rpm -qf rpm包名
    6.查该软件包会向系统里面写入哪些文件：执行 rpm -qpl rpm包名
  RPM包的命名规范：name-version-release.os.arch.rpm
    name：程序名称。
    version：程序版本号。
    release（发行号）：用于标识RPM包本身的发行号，与源程序的release号无关。
    os：即说明RPM包支持的操作系统版本。如el6（即rhel6）、centos6、el5、suse11。
    arch：主机平台。如i686、x86_64、amd64、ppc（power-pc）、noarch（即不依赖平台）
    例：bash-4.3.2-5.el6.x86_64.rpm
  软件包的组成部分：
    二进制程序，位于 /bin, /sbin, /usr/bin, /usr/sbin, /usr/local/bin, /usr/local/sbin 等目录中。
    库文件，位于 /lib, /usr/lib, /usr/local/lib 等目录中。Linux中库文件以 .so（动态链接库）或 .a（静态链接库）作为文件后缀名。
    配置文件，位于 /etc 目录中。
    帮助文件：手册, README, INSTALL (/usr/share/doc/)

三、源码安装
    1. 绝大多数开源软件都是直接以原码形式发布的
    2. 源代码一般会被打成.tar.gz的归档压缩文件
    3. 源代码需要编译成为二进制形式之后才能够运行使用
    4. 源代码基本编译流程：
        1）.configure 检查编译环境；
        2）make对源代码进行编译；
        3）make install 将生成的可执行文件安装到当前计算机中

Telnet服务的配置步骤如下:

安装telnet软件包(通常要两个）
   1、 telnet-client (或 telnet)，这个软件包提供的是 telnet 客户端程序；
   2、 telnet-server ，这个软件包提供的是 telnet 服务器端程序，服务器默认端口号是23
Linux链接
  1、实体链接 hard link
    ln 来源文件 目标文件
    类似创建一个引用，两个文件名指向同一个文件，不会产生新的磁盘空间，删除任何一个对另一个无影响。不能对文件夹使用，不能跨文件系统。
  2、符号链接 symbolic link
    ln -s 来源文件 目标文件
    创建一个新文件，指向源文件，文件名后会跟一个->符号，指向源文件。源文件删除，目标就会打不开。类似windows的快捷方式
新的目录的link数为2，而上层目录的link数则会增加 1

export xxx 来使变量xxx变成环境变量。例：export myName (将myName变量设置为环境变量，其他子程序也能通过$myName访问)
env/export 查看所有环境变量
source FileName 在当前bash环境下读取并执行FileName中的命令。例：source /etc/profile 重新设置环境变量
sh fileName 重新建立一个子shell，在子shell中执行脚本里面的语句，该子shell继承父shell的环境变量，但子shell新建的、改变的变量不会被带回父shell，除非使用export
./fileName 和sh fileName一样，”.”是用来表示当前目录的
> 将标准输出覆盖写入指定文件
>> 将标准输出追加写入指定文件
2> 将标准错误输出覆盖写入指定文件
2>> 将标准错误输出追加写入指定文件
> a.txt 2>&1 将标准输出和错误输出都写入a.txt文件
/dev/null 黑洞文件，写入的数据被丢弃
cmd;cmd 连续下达指令
cmd1&&cmd2 cmd1执行完毕并正确，则继续执行cmd2
cmd1||cmd2 cmd1执行完毕并错误，则继续执行cmd2
cat a.txt | wc 统计a.txt有多少行、字数、字符数
grep 'the' a.txt 查找a.txt中包含the的行
grep '^the' a.txt 查找a.txt中以the开头的行
grep 'the$' a.txt 查找a.txt中以the结尾的行
find / -name check.sh 全局查找check.sh文件
alias psf='ps -ef|grep' 指令设置别名
永久生效
  vim /root/.bashrc
  source /root/.bashrc
test -e fileName  判断文件fileName是否存在
AWK 是一种处理文本文件的语言，是一个强大的文本分析工具

~代表你的/home/用户明目录，假设你的用户名是x，那么~/就是/home/x/   如果以root账号登陆 ~ 是 /root/
.开头的文件名是一个隐藏文件，需要用ls -a查看

Linux修改最大文件打开数
  ulimit -a 查看当前用户可使用系统资源的一些参数，包括可打开的最大文件数量
  ulimit -n 直接查看当前进程可以打开文件的最大数量
  ulimit -a 65535 可以修改最大文件数量，但是只限于当前shell环境
  单进程
    echo "* soft nofile 65535" >> /etc/security/limits.conf
    echo "* hard nofile 65535" >> /etc/security/limits.conf
  整个系统
    修改/etc/sysctl.conf，增加fs.file-max=35942900

  注意：退出当前shell就可以看到修改生效

tar -czvf admin.tar.gz admin admin_client --exclude='admin/logs'  打包并压缩admin文件夹、admin_client文件夹到admin.tar.gz，并且排除admin/logs文件夹
tar -xzvf admin.tar.gz 解压admin.tar.gz
iftop -N -n -i eth0 监控流量

df -h 查看磁盘空间
du -sh * |grep G  查看当前目录下占用磁盘空间1G以上的文件夹

netstat -lnp |grep pid  查看某个进程占用的端口号

sh -[nvx] scripts.sh
选项与参数：
-n 不要执行script，仅查询语法问题
-v 在执行script前，打印script的内容到屏幕上
-x 将使用到的script内容显示到屏幕上。可以用来调试脚本

Linux账号文件：
  /etc/passwd  存放所有账号，每一行代表一个账号，冒号分隔
  /etc/shadow  存放账号密码相关，冒号分隔
  /etc/group   存放所有群组，冒号分隔
useradd dxl 添加账号dxl
passwd dxl  为dxl账号设置密码
userdel dxl 删除账号dxl
id dxl 查看dxl的账号信息

w或者who查看当前已登陆系统的账号
mail命令可以发邮件和查看邮件


分布式事物：
  定义：分布式事务就是为了保证不同数据库的数据一致性
  事务的ACID特性
      1、原子性（A）
      所谓的原子性就是说，在整个事务中的所有操作，要么全部完成，要么全部不做，没有中间状态。对于事务在执行中发生错误，所有的操作都会被回滚，整个事务就像从没被执行过一样。
      2、一致性（C）
      事务的执行必须保证系统的一致性，就拿转账为例，A有500元，B有300元，如果在一个事务里A成功转给B50元，那么不管并发多少，不管发生什么，只要事务执行成功了，那么最后A账户一定是450元，B账户一定是350元。
      3、隔离性（I）
      所谓的隔离性就是说，事务与事务之间不会互相影响，一个事务的中间状态不会被其他事务感知。
      4、持久性（D）
      所谓的持久性，就是说一单事务完成了，那么事务对数据所做的变更就完全保存在了数据库中，即使发生停电，系统宕机也是如此。
  常见的分布式事务解决方案
    1、基于XA协议的两阶段提交
       XA是一个分布式事务协议，由Tuxedo提出。XA中大致分为两部分：事务管理器和本地资源管理器。
       其中本地资源管理器往往由数据库实现，比如Oracle、DB2这些商业数据库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚。串行化隔离级别来保证分布式事务一致性,性能不是很好
       第一阶段 ：事务管理器<--预备、就绪-->本地资源管理器
       第二阶段 ：事务管理器<--提交、成功-->本地资源管理器
       基于 XA 协议实现的分布式事务并不能提升热点并发性能，其意义在于横向扩展资源提升非热点数据并发性能时，能严格保证对多资源访问时的事务 ACID 特性
    2、消息事务+最终一致性
       所谓的消息事务就是基于消息中间件的两阶段提交，本质上是对消息中间件的一种特殊利用，
       它是将本地事务和发消息放在了一个分布式事务里，保证要么本地操作成功成功并且对外发消息成功，要么两者都失败，开源的RocketMQ就支持这一特性
       通过不断执行回调接口检测上个操作是否成功
    3、TCC编程模式
       所谓的TCC编程模式，也是两阶段提交的一个变种。TCC提供了一个编程框架，将整个业务逻辑分为三块：Try、Confirm和Cancel三个操作。
       以在线下单为例，Try阶段会去扣库存，Confirm阶段则是去更新订单状态，如果更新订单失败，则进入Cancel阶段，会去恢复库存。
       总之，TCC就是通过代码人为实现了两阶段提交，不同的业务场景所写的代码都不一样，复杂度也不一样，因此，这种模式并不能很好地被复用
    seata:阿里开源的分布式事务框架

C#
    internal（内部）：限定的是只有在同一程序集中可访问，可以跨类
    protected（受保护）：限定的是只有在继承的子类中可访问，可以跨程序集
    protected internal：受保护“或”内部修饰符修饰成员,当父类与子类在同一个程序集中，internal成员可见

在线分析GC工具
https://gceasy.io/
在线dump文件分析
http://fastthread.io/

Linux查看物理CPU个数、核数、逻辑CPU个数
# 总核数 = 物理CPU个数 X 每颗物理CPU的核数
# 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数

# 查看物理CPU个数
cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l

# 查看每个物理CPU中core的个数(即核数)
cat /proc/cpuinfo| grep "cpu cores"| uniq

# 查看逻辑CPU的个数
cat /proc/cpuinfo| grep "processor"| wc -l
复制代码
 查看CPU信息（型号）
cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c

java在windows，linux上使用的都是一对一模型。如果是N：1，那么进行一次io，进程内的所有其他线程都要阻塞了

Linux查看端口占用
netstat -tunlp|grep 端口号

vmstat详解
  字段说明：
  Procs（进程）：
    r: 运行队列中进程数量，这个值也可以判断是否需要增加CPU。（长期大于1）
    b: 等待IO的进程数量
  Memory（内存）：
    swpd: 使用虚拟内存大小
    注意：如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。
    free: 空闲物理内存大小
    buff: 用作缓冲的内存大小
    cache: 用作缓存的内存大小
    注意：如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小。
  Swap：
    si: 每秒从交换区写到内存的大小，由磁盘调入内存
    so: 每秒写入交换区的内存大小，由内存调入磁盘
    注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。
  IO：（现在的Linux版本块的大小为1kb）
    bi: 每秒读取的块数
    bo: 每秒写入的块数
    注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。
  系统：
    in: 每秒中断数，包括时钟中断。
    cs: 每秒上下文切换数。
    注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。
  CPU（以百分比表示）：
    us: 用户进程执行时间百分比(user time)
    注意： us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。
    sy: 内核系统进程执行时间百分比(system time)
    注意：sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。
    wa: IO等待时间百分比
    注意：wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。
    id: 空闲时间百分比

top命令：M 按内存排序；P 按cpu排序；N 按pid排序；q 退出；1 查看多核cpu信息
killall -i -9 java 杀掉所有java命令开启的进程（-i 一个个询问）

积分和微分是一对互逆运算，这是微积分最核心的思想
微积分基本定理的核心思想就是用求原函数的方式来解决求面积的问题
求面积（积分）和求导（微分）是一对互逆运算
积分：一条曲线y=f(x)和x轴在a和b之间围成的面积。把x分的足够小，就可以看成是无数个矩形组成的图形，由无数个无穷小的面积组成的面积
微分：斜率等于在直线上两点的纵坐标之差Δy和横坐标之差Δx的比值，即Δy/Δx
     莱布尼茨就给这两个趋近于0却又不等于0的Δx和Δy重新取了一个名字：dx和dy，并把它们称为“微分”

lscpu

java中内码（运行内存）中的char使用UTF16的方式编码，一个char占用两个字节，但是某些字符需要两个char来表示。所以，一个字符会占用2个或4个字节。
java中外码中char使用UTF8的方式编码，一个字符占用1～6个字节。
UTF16编码中，英文字符占两个字节；绝大多数汉字（尤其是常用汉字）占用两个字节，个别汉字（在后期加入unicode编码的汉字，一般是极少用到的生僻字）占用四个字节。
UTF8编码中，英文字符占用一个字节；绝大多数汉字占用三个字节，个别汉字占用四个字节。

GMT：格林尼治标准时间。根据地球的自转和公转来计算时间，但是地球越转越慢，所以这个时间慢慢就会误差越大
UTC：协调世界时，别称：世界统一时间，世界标准时间。根据原子钟来计算时间，5050亿年才会误差1秒
GMT并不等于UTC，而是等于UTC+0，只是格林尼治刚好在0时区上，由于 UTC+0 的特殊性，所以有时也把 GMT 当成参照，以下写法等同，例如：北京时间(CST)= UTC+8 = GMT+8
GMT: UTC +0    =    GMT: GMT +0
CST: UTC +8    =    CST: GMT +8
PST: UTC -8    =    PST: GMT -8
夏令时：表示为了节约能源，人为规定时间的意思，又称“日光节约时制”和“夏令时间”。
具体做法是：每年从四月中旬第一个星期日的凌晨2时整（北京时间），将时钟拨快一小时，即将表针由2时拨至3时，夏令时开始；
          到九月中旬第一个星期日的凌晨2时整（北京夏令时），再将时钟拨回一小时，即将表针由2时拨至1时，夏令时结束。

获取系统时间戳无关时区，不同时区只要时间是准确的，同时获取的时间戳是一样的
