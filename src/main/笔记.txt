Synchronize语义规范：
  1、进入同步块前，先清空工作内存中的共享变量，从主内存中重新加载（也能实现变量的可见性）
  2、解锁前必须把修改的共享变量同步回主内存
volatile语义规范：
  1、使用volatile变量时，必须重新从主内存加载，并且read、load是连续的
  2、修改volatile变量后，必须立马同步回主内存，并且store、write是连续的

-------------------JVM运行时数据区-------------------
一、线程共享部分
  1、方法区
     存储加载的类信息、常量、静态变量、JIT编译后端代码数据
  2、堆内存
     存放对象实例，几乎所有对象、数组都放这里
     回收判断：引用计数器法、可达性分析算法
     默认比例：老年代占2/3，新时代占1/3（Eden占8/10，s0占1/10，s1占1/10）
     JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。
     因此，新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间
二、线程独占部分
  1、虚拟机栈
     线程中方法执行的模型，每个方法执行时，就会在虚拟机中创建一个栈帧，每个方法从调用到执行的过程，就对应着栈帧在虚拟机中从入栈到出栈的过程
     栈帧包括：局部变量表（存放局部变量基础类型值），局部对象的引用，操作数栈（存放临时变量），返回值地址
  2、本地方法栈
     和虚拟机栈类似，虚拟机栈是为执行java方法而准备的。本地方法栈是为虚拟机使用native方法而准备的
  3、程序计数器
     记录cpu执行到字节码指令的位置，线程切换需要

直接内存：JVM之外的内存，开发人员自己分配和回收内存


Lock和synchronized的选择
  1、Lock是接口，而synchronized是java中的关键字
  2、synchronized不会导致死锁，而Lock可能造成死锁现象
  3、Lock可以让等待锁的线程响应中断，而synchronized却不行
  4、通过Lock可以知道有没有成功获得锁，而synchronized却无法办到
  5、Lock可以提供多个线程进行读操作
  6、当竞争资源非常激烈时，Lock的性能要远远大于synchronized

自旋锁（spinlock）：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环（减少了上下文切换）

synchronized的锁升级:
  对象头里保存了锁的状态：无锁、偏向锁、轻量级锁、重量级锁。锁只能升级不能降级
  1、偏向锁：默认这个锁属于A，当A再次拿锁就直接给他，B来拿锁，发现是偏向A的，就去尝试获取锁，成功了就偏向B，否则升级为轻量级锁。用CAS设置偏向锁
  2、轻量级锁：A获取了锁，B来拿锁，先自旋一段时间，如果自旋完还没拿到锁就升级到重量级锁，B阻塞
  3、重量级锁：A获取了锁，B来拿锁，没拿到就直接阻塞了

分布式锁实现的几种方案
  1、数据库实现（乐观锁）
  2、基于zookeeper实现
  3、基于redis实现。redis调用lua脚本，原子操作设置key和超时时间。推荐redission包，redis官方jar包

常用的数据库优化方法：
  1、建索引
  2、分区表

索引的原理：
  对列值创建排序存储，数据结构={列值、行地址}。在有序的数据列表中就可以利用二分查找快速找到要查找的行地址，在根据地址直接取行数据
  mysql使用B+树存储索引

唯一id生成方法：
  1、UUID
  2、数据库自增，分库分表的时候可以设置不同表的起始值和步长不同达到全局唯一的效果
  3、雪花算法
  4、redis
  5、AtomicInteger

弱引用--WeekReference
  当一个对象仅仅被weak reference指向, 而没有任何其他strong reference指向的时候, 如果GC运行, 那么这个对象就会被回收

软引用--SoftReference
  用法和弱引用一样，回收的时候再加一个条件：内存不足的时候才会回收

GC roots
  1、通过System Class Loader或者Boot Class Loader加载的class对象
  2、线程栈变量
  3、静态变量
  4、常量池
  5、jni指针
  6、正在被用于同步的各种锁对象
GC 算法
  1、标记清除
  2、复制
  3、标记整理
永久代和元空间区别：
  1、永久代必须指定大小，元空间默认无上限
  2、字符串常量1.7放永久代，1.8后放在堆里
  3、元空间由操作系统管理
jvm GC
  Minor GC：清理新生代，Eden区满了会触发一次（把根引用对象复制到s0或者s1区域，并且把对象的分代年龄+1，分带年龄大于15的对象会进入到老年代。可回收对象就直接清理掉）
  Major GC：Full GC
  Full GC：清理整个堆，包括新生代和老年代
  https://www.cnblogs.com/yuyutianxia/p/8986902.html
  shallow heap：这个对象实际占用的堆大小（ 类定义引用大小 + 父类的成员变量所占的空间 + 当前类的成员变量所占的空间 + 结构体对齐）
  retained heap：如果这个对象被删除了（GC回收掉），能节省出多少内存
  -XX:SurvivorRatio=6 ，设置的是Eden区与每一个Survivor区的比值，可以反推出占新生代的比值，Eden为6, 两个Survivor为2, Eden占新生代的3/4, 每个Survivor占1/8，两个占1/4

Full GC触发条件：
  1、System.gc()方法的调用。此方法的调用是建议JVM进行Full GC,虽然只是建议而非一定，但很多情况下它会触发 Full GC
  2、老年代空间不足。新生代对象转入 或者 创建为大对象、大数组时 发现老年代空间不足
  3、方法区空间不足。CMS GC可避免这个问题
  4、判断当前新生代的对象是否能够全部顺利的晋升到老年代，如果不能，就提早触发一次老年代的收集
  5、CMS GC时出现promotion failed和concurrent mode failure时：进行Minor GC时，survivor space放不下, 对象只能放入老年代，而此时老年代也放不下

如何减少Full GC次数：
  1、尽量做到让对象在Minor GC阶段被回收、让对象在新生代多存活一段时间（加大新生代的空间，降低Minor GC的频率）
  2、不要创建过大的对象及数组（因为数组需要连续空间）
  3、CMS模式里，Full GC之后额外免费赠送一个碎片整理的过程。XX:+UseCMSCompactAtFullCollection（默认开启的）
     执行多少次不压缩的Full GC后,跟着来一次带压缩的。-XX:CMSFullGCsBeforeCompaction （默认值为0，表示每次Full GC是都进行碎片整理），可降低STW的时间
  4、禁止使用System.gc()方法

CMS收集器：
  过程：初始标记、并发标记、重新标记、并发清除
  缺点：1、对CPU资源敏感。默认启动回收线程数=(CPU数量+3)/4，CPU小于4个的时候，对CPU资源占用较大
        2、无法处理浮动垃圾，并发清除阶段，用户线程会产生新的垃圾，CMS只能下次回收
  -XX:CMSInitiatingOccupancyFraction = 92 ：当老年代内存使用了92%就启用CMS收集。这个值如果设置的太大，那么导致并发清除的时候，预留给用户线程的内存不够，
     会出现Concurrent Mode Failure失败。这时候jvm会启动Serial Old收集器来重新收集老年代，这样停顿的时间就长了

G1（Garbage First）收集器：
  开启选项：-XX:+UseG1GC
  使用copy算法
  化整为零的思路：将java堆划分为多个大小相等的独立区域（Region）
  可停顿的预测：使用者可以明确指定在M毫秒的时间片段内，GC不超过N毫秒
  维护一个优先级列表，优先回收价值最大的Region
  运作期间不会产生内存空间碎片，收集后能提供连续的可用内存
  过程：初始标记、并发标记、最终标记、筛选回收

jvm参数分类：
  1、-开头，所有HotSpot都支持
  2、-X开头，特定Hotspot版本支持
  3、-XX开头，下个版本可能取消


netty两个线程池作用
  一个负责接受客户端的TCP连接
  一个负责处理I/O相关的读写操作，或执行系统task、定时task。一个线程对应多个链路，一个链路对应一个线程，避免并发

redis慢查询日志：
  slowlog-log-slower-than：慢查询预定阀值
  slowlog-max-len:先进先出队列的长度，超过长度后新日志进入会删除老日志（所以可以定期用slowlog get命令获取日志并保持到mysql里）
  慢查询日志记录的是命令执行时间超过阀值的命令，客户端命令执行时间 = 排队等待时间 + 执行时间 + 网络传输时间
  当客户端命令执行时间过长，排查过程：如果慢查询日志里没有，用redis监控看连接数是否大于最大连接数，看是否RDB占用了很多时间

类加载过程：
  加载-->验证-->准备-->解析-->初始化
  内部类只有在使用的时候才会被加载，可利用这一特性写单例模式（避免过早初始化的问题）
  枚举不能被反射创建

aop 应用场景：日志，事务，权限,参数校验
    实现原理是动态代理
    spring的AOP实现
    1、jdk动态代理
    2、采用Cglib动态代理可以对没有实现接口的类产生代理，实际上是生成了目标类的子类来增强。
mybatis的Mapper使用了动态代理创建Dao
静态代理模式：
   接口
   被代理类：实现接口
   代理类：实现接口 + 引用真实类
   这样代理就可以对外提供接口的所有方法（可选择用被代理类实现，或自己实现这些方法）
动态代理模式：
   反射方式实现，避免实现所有接口的所有方法(jdk动态帮我们创建一个类(字节码文件),以$Proxy开头)
   代理类的调用方法
   invoke（Method method）{
      if(method 是需要我自己实现的){
         我就自己实现
         return
      }
      //被代理类去实现
      method.invoke()
   }


class文件的开头是一个魔数：0xCAFEBABE
mybatis分页插件

线程池执行任务流程：
   1 使用核心线程执行
   2 核心线程数满了，放入队列
   3 队列满了，使用临时线程
   4 临时线程数满了，使用拒绝策略

线程池大小设置：
cpu密集型：cup核心数 + 1
io密集型：cup核心数 * 2
实际应用：cup核心数 *（1 + 线程等待时间 / 线程运行时间）

TCP三次握手：
   可以理解为应该4次握手合并成了三次，每个端都需要一问一答才能确立连接。
   c问s答，c确认建立连接；s问c答，s确认建立连接。syn是问，ack是答
   但是服务器把答（ack）和问（syn）一次性发送过去了。
   第三次握手是为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误。
TCP四次挥手：
   每个端都需要一问一答才能确认关闭 。请求关闭（FIN），回答（ACK）
   为什么不是三次？
   因为服务器的问答不能合并发送了
   因为服务端接到客户端关闭请求后，自己可能还有消息要处理，所以不能立马告诉客户端我要关闭，要等消息处理完再发送关闭请求。
   服务器比客户端先关闭连接，因为客户端发送最后一个ack后，会启动一个计时器。计时器到了，才关闭连接。而服务器接收到ack就立马close。这么做是防止最后一个ack丢失
TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。
服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。
若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接

UDP是无连接通信协议，即在数据传输时，数据的发送端和接收端不建立逻辑连接。简单来说，当一台计算机向另外一台计算机发送数据时，发送端不会确认接收端是否存在，就会发出数据，同样接收端在收到数据时，也不会向发送端反馈是否收到数据。
由于使用UDP协议消耗资源小，通信效率高，所以通常都会用于音频、视频和普通数据的传输例如视频会议都使用UDP协议，因为这种情况即使偶尔丢失一两个数据包，也不会对接收结果产生太大影响。
但是在使用UDP协议传送数据时，由于UDP的面向无连接性，不能保证数据的完整性，因此在传输重要数据时不建议使用UDP协议。
UDP传输数据被限制在64K以内。

Snappy压缩库
Snappy是Google开源的压缩/解压缩库。和其他压缩库相比，snappy的压缩率并不是最高的，兼容性也并非最好的。相反，它的诞生旨在以极高的压缩/解压缩速率提供合理的压缩率。
Snappy官指出：在64位单核core-i7处理器下，snappy的压缩率能够达到250MB/S，而解压缩速度则能达到500MB/S。
目前很多软件使用（或支持）snappy作为压缩库，如MongoDB,Cassandra,Hadoop,Lucene

迭代器
  一种设计模式
  不同集合的内部数据结构不一样，遍历方式也不一样。利用迭代器统一实现遍历，不同集合内部实现方式不一样，但是对外使用都是一样的。
  Iterable 接口提供获取Iterator方法，并且实现这个接口可以用foreach遍历
  Iterator 提供遍历的方法

clone
  Object的clone方法是native方法，是protected，只有子类能调用
  子类只有实现了Cloneable接口才能调用Object的clone()方法，否则报错
  Object的clone()方法会创建一个新对象，对象的成员变量和老的对象一样，包括基础类型和引用类型

java使用Unicode编码：Unicode编码则是采用双字节16位来进行编号，可编65536字符，是全世界一种通用的编码

线程安全的list
  1、CopyOnWriteArrayList
  2、Collections.synchronizedList(new ArrayList<>())
  3、Vector
    Vector，它是ArrayList的线程安全版本，其实现90%和ArrayList都完全一样，区别在于：
    1、Vector是线程安全的，ArrayList是线程非安全的
    2、Vector可以指定增长因子，如果该增长因子指定了，那么扩容的时候会每次新的数组大小会在原数组的大小基础上加上增长因子；
       如果不指定增长因子，那么就给原数组大小*2
线程安全的map
  1、HashTable
  2、Collections.synchronizedMap(new HashMap<>())
  3、ConcurrentHashMap
线程安全的queue
  1、ConcurrentLinkedQueue  全程采用cas，无锁操作，避免线程的上下文切换。无法设置队列大小
  2、ArrayBlockingQueue   put 和 get 用同一个 ReenterLock。Condition实现阻塞，唤醒。不会封装Node节点，减少对象的创建。必须设置大小
  3、LinkedBlockingQueue  put 和 get 锁分离。Condition实现阻塞，唤醒。可以设置队列大小
  4、LinkedTransferQueue
     LinkedTransferQueue采用一种预占模式。意思就是消费者线程取元素时，如果队列不为空，则直接取走数据，
     若队列为空，那就生成一个节点（节点元素为null）入队，然后消费者线程被等待在这个节点上，
     后面生产者线程入队时发现有一个元素为null的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，
     被唤醒的消费者线程取走元素，从调用的方法返回。我们称这种节点操作为“匹配”方式。
  5、PriorityBlockingQueue
  6、SynchronousQueue
    SynchronousQueue是一个内部只能包含一个元素的队列。
    插入元素到队列的线程被阻塞，直到另一个线程从队列中获取了队列中存储的元素。
    同样，如果线程尝试获取元素并且当前不存在任何元素，则该线程将被阻塞，直到线程将元素插入队列
  7、Disruptor
  https://www.jianshu.com/p/ae6977886cec

缓存穿透：请求数据，在redis里没找到，然后到数据库去查找也没找到，这个就叫穿透。用户可以用很多无效id请求攻击服务器，占用数据库资源。
解决方案：布隆过滤器，将id用多个hash算法计算出多个指纹，将指纹放入bitmap里。如果布隆过滤器说没有那就一定没有，说有那就可能有。
          布隆过滤器可用于海量数据里判断出某个数据是否存在
缓存击穿：当缓存key失效的瞬间，大量请求访问key，造成数据库压力过大
解决方案：设置互斥锁，当缓存不存在，尝试去获取锁，获取到锁了去数据库加载并设置到缓存；没有获取到锁就休眠一会再获取数据

缓存雪崩：大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩
解决方案：可以给缓存设置过期时间时加上一个随机值时间，使得每个key的过期时间分布开来，不会集中在同一时刻失效

redis数据淘汰策略
    1、volatile-lru:从已设置过期的数据集中挑选最近最少使用的淘汰
    2、volatile-ttr:从已设置过期的数据集中挑选将要过期的数据淘汰
    3、volatile-random:从已设置过期的数据集中任意挑选数据淘汰
    4、allkeys-lru:从数据集中挑选最近最少使用的数据淘汰
    5、allkeys-random:从数据集中任意挑选数据淘汰
    6、noenviction:禁止淘汰数据（默认），直接oom
    这些挑选都是随机的挑选一些数据，再利用规则淘汰
    当内存达上限的时候，redis会启动淘汰机制。redis淘汰数据时还会同步到aof中、从机

redis实现mq
  1、redis的列表键，lpush 放表头,rpop 表尾删除
  2、订阅/发布模式

strace -ff -o out /usr/java/bin/java TestOldSocket    Linux追踪java程序，输入到out开头的文件
netstat -natp  查看tpc状态，谁和谁连接了，那个端口在监听

设计模式：
  单例模式
  工厂模式
  观察者模式
  适配器模式
  装饰器模式
  代理模式
  责任链模式
  状态模式

TreeMap：基于红黑二叉树的NavigableMap的实现，线程非安全。可以对key进行排序
sleep()与wait()方法都不占用cpu时间及利用率,不会释放锁
多线程的五大状态：
  创建状态
  就绪状态
  阻塞状态
  运行状态
  死亡状态

一致性hash
  简单hash：当节点变化的时候，所有数据都得重新hash，变动，一致性hash解决这个问题
  把hash值分布在0-2的32次方，首尾相接的圆环。
  首先求出服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）上。
  然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。
  然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台服务器上
  使用虚拟节点解决数据倾斜问题

tomcat基本结构
  1、server：只有一个，掌管着整个Tomcat的生死大权，包含多个service
  2、service：包含多个connector和一个container
  3、connector：处理连接相关的事情，并提供Socket与Request和Response相关的转化，封装好后丢给container
  4、container：封装和管理Servlet，以及具体处理Request请求。包含一个engine
  5、engine：引擎，用来管理多个站点，将传入请求委托给适当的虚拟主机处理。包含多个host
  6、host：代表一个站点，也可以叫虚拟主机。主要概念：主机的域名和根目录。包含多个context
  7、context：代表一个web应用，包含多个wrapper
  8、wrapper：代表一个servlet
  Container处理请求是使用Pipeline-Value管道(责任链模式)来处理的
tomcat优化：
  1、设置connector的协议（nio、bio、apr）tomcat 8.0默认是NIO
  2、设置connector的线程池大小，默认最大线程数是200
  3、关闭host的unpackWARs（自动解压war包）、autoDeploy（自动部署），可以节省一个线程
  4、关闭context的reloadable（热更新class），节省线程
  5、设置jvm参数，内存占用什么的

AQS（抽象的队列式同步器）原理
  1、state      标记锁的状态，获取锁的线程数。读写锁里：高16位表示读锁状态，低16位表示写锁状态
  2、双向队列   存放阻塞线程
  3、CAS        改变锁的状态、节点状态，设置头结点、尾节点
  4、自旋       被唤醒的线程会自旋，尝试获取锁
  5、保存已经获得锁的线程，实现重入
